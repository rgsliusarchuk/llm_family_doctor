#!/usr/bin/env python
"""Streamlit-Ñ–Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ MVP Â«LLM-Ğ°ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ ÑÑ–Ğ¼ĞµĞ¹Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ñ–ĞºĞ°Ñ€ÑÂ»."""
from __future__ import annotations
import csv
import datetime as dt
import os
import sys
from pathlib import Path

# Add current directory to Python path for imports
sys.path.append(str(Path(__file__).parent))

# Disable tokenizers parallelism to avoid warnings in multiprocessing
os.environ["TOKENIZERS_PARALLELISM"] = "false"

import streamlit as st
from dotenv import load_dotenv

# â”€â”€ env & settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

from src.config import settings

# â”€â”€ local modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Try to use LangChain components first, fallback to original if not available
try:
    from src.models.rag_chain import generate_rag_response
    USE_LANGCHAIN = True
except ImportError:
    from src.models.vector_store import search
    from src.models.llm_client import generate_response
    USE_LANGCHAIN = False

# â”€â”€ Streamlit Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ° ĞºĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="LLM-Ğ°ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚", page_icon="ğŸ©º")
st.title("LLM-Ğ°ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ ÑÑ–Ğ¼ĞµĞ¹Ğ½Ğ¾Ğ³Ğ¾ Ğ»Ñ–ĞºĞ°Ñ€Ñ â€” MVP")

# â”€â”€ Sidebar (Ğ»Ğ¸ÑˆĞµ Ğ¿ĞµÑ€ĞµĞ³Ğ»ÑĞ´ ĞºĞ¾Ğ½Ñ„Ñ–Ğ³Ñƒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.caption("âš™ï¸ ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ (read-only)")
    st.write(f"**Embedding-Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ:** `{settings.model_id}`")
    st.write(f"**Ğ†Ğ½Ğ´ĞµĞºÑ:** `{settings.index_path}`")
    st.write(f"**Doc-map:** `{settings.map_path}`")
    st.write(f"**LangChain:** {'âœ… Enabled' if USE_LANGCHAIN else 'âŒ Disabled'}")
    if hasattr(settings, 'langsmith_project'):
        st.write(f"**LangSmith:** `{settings.langsmith_project}`")

# â”€â”€ Ğ¿Ğ¾Ğ»Ğµ Ğ²Ğ²ĞµĞ´ĞµĞ½Ğ½Ñ ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ñ–Ğ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
symptoms = st.text_area(
    "ĞĞ¿Ğ¸Ñ ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ñ–Ğ² Ğ¿Ğ°Ñ†Ñ–Ñ”Ğ½Ñ‚Ğ°",
    placeholder="ĞĞ°Ğ¿Ñ€.: Ğ±Ñ–Ğ»ÑŒ Ñƒ Ğ³Ğ¾Ñ€Ğ»Ñ–, Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° 38 Â°C, ĞºĞ°ÑˆĞµĞ»ÑŒ 3 Ğ´Ğ½Ñ–â€¦"
)

# â”€â”€ ĞºĞ½Ğ¾Ğ¿ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ñ–Ñ— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if st.button("Ğ—Ğ³ĞµĞ½ĞµÑ€ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ¿Ğ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ Ğ´Ñ–Ğ°Ğ³Ğ½Ğ¾Ğ·", type="primary"):
    if not symptoms.strip():
        st.warning("Ğ‘ÑƒĞ´ÑŒ Ğ»Ğ°ÑĞºĞ°, Ğ²Ğ²ĞµĞ´Ñ–Ñ‚ÑŒ ÑĞ¸Ğ¼Ğ¿Ñ‚Ğ¾Ğ¼Ğ¸.")
        st.stop()

    if USE_LANGCHAIN:
        # Use LangChain RAG pipeline
        with st.spinner("Ğ“ĞµĞ½ĞµÑ€ÑƒÑ”Ğ¼Ğ¾ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ (LangChain)â€¦"):
            result = generate_rag_response(symptoms, top_k=3)
            answer = result["response"]
            retrieved_docs = result["documents"]
    else:
        # Fallback to original implementation
        retrieved = search(symptoms, top_k=3)
        if not retrieved:
            st.error("ĞĞµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ñ–Ğ².")
            st.stop()

        context = "\n\n".join(snippet for _, snippet in retrieved)

        with st.spinner("Ğ“ĞµĞ½ĞµÑ€ÑƒÑ”Ğ¼Ğ¾ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒâ€¦"):
            answer = generate_response(symptoms, context)
        
        # Convert to document format for consistency
        retrieved_docs = []
        for score, snippet in retrieved:
            from langchain.schema import Document
            doc = Document(
                page_content=snippet,
                metadata={"similarity_score": score}
            )
            retrieved_docs.append(doc)

    # 3) Ğ²Ñ–Ğ´Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ½Ñ
    st.markdown("## ĞŸĞ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ Ğ´Ñ–Ğ°Ğ³Ğ½Ğ¾Ğ· Ñ– Ğ¿Ğ»Ğ°Ğ½ Ğ»Ñ–ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ")
    st.markdown(answer)

    with st.expander("ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚Ğ¸ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ñ– Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ¸"):
        for i, doc in enumerate(retrieved_docs, 1):
            score = doc.metadata.get("similarity_score", 0.0)
            st.markdown(f"**ĞŸÑ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» {i}** (ÑÑ…Ğ¾Ğ¶Ñ–ÑÑ‚ÑŒ: {score:.3f})  \n{doc.page_content}\n\n---")

    # â”€â”€ Ñ†Ğ¸ĞºĞ» ÑÑ…Ğ²Ğ°Ğ»ĞµĞ½Ğ½Ñ Ğ»Ñ–ĞºĞ°Ñ€ĞµĞ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    col1, col2, col3 = st.columns(3)
    feedback_log = Path("logs/doctor_feedback.csv")
    feedback_log.parent.mkdir(parents=True, exist_ok=True)

    def log_feedback(status: str, edited: str | None = None):
        with feedback_log.open("a", newline="", encoding="utf-8") as f:
            csv.writer(f).writerow(
                [dt.datetime.now().isoformat(), symptoms, status, edited or answer]
            )

    with col1:
        if st.button("Ğ¡Ñ…Ğ²Ğ°Ğ»Ğ¸Ñ‚Ğ¸"):
            log_feedback("approved")
            st.success("Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ ÑÑ…Ğ²Ğ°Ğ»ĞµĞ½Ğ¾ Ñ‚Ğ° Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾.")
    with col2:
        if st.button("Ğ’Ñ–Ğ´Ñ…Ğ¸Ğ»Ğ¸Ñ‚Ğ¸"):
            log_feedback("rejected")
            st.warning("Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ²Ñ–Ğ´Ñ…Ğ¸Ğ»ĞµĞ½Ğ¾ Ñ‚Ğ° Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾.")
    with col3:
        edited = st.text_area("âœï¸ Ğ’Ñ–Ğ´Ñ€ĞµĞ´Ğ°Ğ³ÑƒĞ¹Ñ‚Ğµ Ğ¿ĞµÑ€ĞµĞ´ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ½ÑĞ¼:", value=answer)
        if st.button("Ğ—Ğ±ĞµÑ€ĞµĞ³Ñ‚Ğ¸ Ñ€ĞµĞ´Ğ°Ğ³Ğ¾Ğ²Ğ°Ğ½Ğµ"):
            log_feedback("edited", edited)
            st.success("Ğ ĞµĞ´Ğ°Ğ³Ğ¾Ğ²Ğ°Ğ½Ñƒ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ·Ğ±ĞµÑ€ĞµĞ¶ĞµĞ½Ğ¾.")